{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the test/valid and oob datasets\n",
    "\n",
    "**what is the difference between machine learning and anyother task?**\n",
    "Machine learning focuses on generalizing the model over the data, this helps in understanding and creating a model that could work on any data with similar accuracy. This is important as once the model is ready that targets one problem it can be used with sligthest tweaks on any other similar data.\n",
    "The generalization of the model can be checked by taking a random sample and use that as the test set. Along with the test set we should also take another random set called the validation set that helps in validating the genaralization of the model. This validation set is used because if we just simply have the testing set the model may not work properly the first time so we tweak and come up with another model, again it fails at the test set and may be @25th time it works but this works only for that test set. Inorder to not have to run into that issue, we create a validation set which validates for generalization when the model works well with that model then we check with the test set and there by come to a conclusion that the model is genarlized.\n",
    "\n",
    "There is another method to perform generalization with out creating a validation set for RF, this can be done by using OOB sampling, hence this helps in validating the model for generalization. Though this method of using OOB score is a good method but it provides a lesser accuracy when compared to that of the validation set, this is because validation set works with the same dataset over the complete RF model, but the OOB sampling is sub sample that is used to test a set of trees or models in the complete forest. It is a very subtle difference but it is good to practice with the validation set.\n",
    "\n",
    "**Though it is a good practice to randomly sample to test, why is it not a good practice?**\n",
    "When we build a model it is always into production but the time we use it in real time, there is a delay in the usage period to that of the model building period. Since the practices/ trends of the people and their lifestyle changes with time, it is always important to remember that the test sample is always the latest and hence that stays pretty close to the time of the usage period. \n",
    "***remember:** While using the data to test, try to have data for testing that is the latest with regards to the testing. This way we can you data that generalizes to data* \n",
    "\n",
    "It is very important to know that the validation set is representing the test set, so to validate we can build 5 models and plot the score of validation set and score of the test set for all the models. Our aim here is to get a linear line between validation set and test set. It is important that we don't look at the test set and we only work with the validation set to perform any feature engineering/ importance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The whole data is split into n times and out of which we use 1 part as a validation set and other parts as training sets to calculate accuracy at every stage. The average of the n models will help us coming to the accuracy of the model. \n",
    "**Benefit and downsides of cross validation over normal validation set**\n",
    "* This way we can use all of the data for the models to test, this way we can understand the model for the complete data.\n",
    "* It takes a lot of time to perform testing as the model has to run over the complete data more than once.\n",
    "* Since the validation sets are random, it is a not a good way to cross validate when we have to work with temporal data. \n",
    "hence it is not a good practice to do cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Interpretation\n",
    "\n",
    "```python\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "```\n",
    "*remember to insert the image of the tree*\n",
    "\n",
    "The tree interpreter for the random forest helps us in undrstanding how each of the split contributed to the prediction of the dependent variable. So, it typically helps us in understanding the different scenarios and its impact on the final output. Ex: works like a Recommender systems. \n",
    "\n",
    "```python\n",
    "prediction, bias, contributions = ti.predict(m,row)\n",
    "\n",
    "[o for o in zip(df.columns[idxs],dfValid.iloc[0][idxs], contribute[0][idxs])]\n",
    "```\n",
    "\n",
    "Using the above code's we can get information about all the levels of the trees and their impact on the final output of the model. With the help of this we can get insights of how a feature is impacting how features are affecting the output so and so forth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolation\n",
    "\n",
    "*This is the last step before building our own random forest*\n",
    "\n",
    "Extrapolation is basically drawing a tangent to the current flow and predict what could be the value in the future. This method of extrapolating is poosible if we have a linear model, but using RF can't really provide an extrapolation easily.\n",
    "\n",
    "**Workarounds for RF**\n",
    "One way is to avoid temporal component from the data to have a model not depend on time. \n",
    "\n",
    "*please redo extrapolation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RF from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
